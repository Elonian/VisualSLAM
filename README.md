This paper presents a Visual-Inertial Simultaneous Localization and Mapping (VI-SLAM) system that integrates an Extended Kalman Filter (EKF) for state estimation and landmark mapping. The approach fuses inertial measurement unit (IMU) data with stereo camera observations to achieve robust localization in dynamic environments. The EKF prediction step employs SE(3) kinematics to propagate the robotâ€™s pose using IMU-derived velocity measurements, while the update step refines the pose based on visual feature observations. Feature detection, stereo matching, and temporal tracking techniques are applied to extract reliable correspondences. To improve computational efficiency and mapping accuracy, unreliable feature points are filtered, and noise parameters are optimized. The proposed method is validated using real-world data from Clearpath Jackal robots operating in an outdoor environment. Experimental results demonstrate accurate trajectory estimation and precise landmark localization, underscoring the effectiveness of IMU-visual fusion in enhancing SLAM performance.
